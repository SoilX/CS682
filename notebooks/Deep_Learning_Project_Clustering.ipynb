{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ln2c_s-EIGGs"
   },
   "source": [
    "<hr/>\n",
    "\n",
    "# Dependencies\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2KFMkLmIGGw"
   },
   "outputs": [],
   "source": [
    "# Calculation Dependencies\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Plotting Dependencies\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing dependencies\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# # maybe useful in future\n",
    "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b24JUkaJoK9"
   },
   "source": [
    "<hr/>\n",
    "\n",
    "#  Helper Functions\n",
    "\n",
    "\n",
    "\n",
    "1.   plot_features - 2d plotting any data array with shape (num_examples, num_features)\n",
    "2.   PCA_iterative - PCA dimensionality reduction based on desired threshold for the explanation of variance\n",
    "3.   kmeans_clustering - performs kmeans clustering based on desired number of clusters \n",
    "\n",
    "\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNkEByiCqwnb"
   },
   "outputs": [],
   "source": [
    "# function that plots every feature against each other\n",
    "def plot_features(data, labels):\n",
    "  \"\"\"\n",
    "  input args:\n",
    "    data = numpy array where rows are number of examples and columns are number of features\n",
    "\n",
    "  \n",
    "  rows are in order by features 1, 2, ...num_features-1 \n",
    "  plotted against every other features that hasn't already been plotted\n",
    "  e.g. row 1 is feature 1 versus 2, 1 versus 3, ...,1 versus num_features\n",
    "  e.g. row 5 is features 5 versus 6, feature 6 versus 7, ..., 5 versus num_features\n",
    "  \"\"\"\n",
    "  num_feature = data.shape[1]\n",
    "  plt.figure(figsize=(num_feature*4,num_feature*4));\n",
    "  for i in range(num_feature):\n",
    "    for j in range(i+1,num_feature):\n",
    "      plt.subplot(num_feature,num_feature,i*num_feature+j-i+1)\n",
    "      plt.scatter(data[:,i],data[:,j],c=labels, label = ('feature ', (i+1), 'versus ', (j+1)))\n",
    "      plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPhqtVe3LIk3"
   },
   "outputs": [],
   "source": [
    "# Preprocessing, note whitening is set to be true\n",
    "# PCA and whitening\n",
    "def PCA_iterative(data, threshold, mode = 'threshold', whiten_bool = 'False', n = 0):\n",
    "  \"\"\"\n",
    "  mode = 'components' does PCA reduction to n components\n",
    "  mode = 'threshold' performs PCA reduction to the fewest components that satisfy a threshold of explained variance\n",
    "  prints out how many components the data was reduced to\n",
    "  prints out \n",
    "  \"\"\"\n",
    "  if mode == 'threshold':\n",
    "    for i in range(2, data.shape[1]+1):\n",
    "      pca = PCA(n_components = i, whiten=whiten_bool)\n",
    "      B = pca.fit_transform(data)\n",
    "      L = pca.explained_variance_\n",
    "      cl=np.cumsum(L); \n",
    "      if (cl[i-2]/cl[-1]) > threshold:\n",
    "        print(\"PCA reduction to \", i, \" components with \", cl[i-2]/cl[-1], \" explained variance\")\n",
    "        break\n",
    "  else:\n",
    "    pca = PCA(n_components = n, whiten=whiten_bool)\n",
    "    B = pca.fit_transform(data) \n",
    "    L = pca.explained_variance_\n",
    "    cl=np.cumsum(L); \n",
    "    print('PCA reduction to ', n, ' components with', cl[i-2]/cl[-1], \" explained variance\")\n",
    "\n",
    "  # PCA scree plot\n",
    "  plt.subplot(111); \n",
    "  plt.ylabel('Total Variance');\n",
    "  plt.xlabel('Principal component')\n",
    "  plt.plot(np.arange(1,L.shape[0]+1),cl/cl[-1],'o-r'); \n",
    "  plt.ylim(0,None);\n",
    "  return B, pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQj-YbofS5Dp"
   },
   "outputs": [],
   "source": [
    "def pseudolabel_unscrambler(label, cluster_label):\n",
    "  \"\"\"\n",
    "  pseudolabels of classes get randomly assigned. This function best matches\n",
    "  the pseudolabels to the original ground truth labels.\n",
    "  \"\"\"\n",
    "  num_class = np.max(label) + 1\n",
    "  true_class = []\n",
    "  for i in range(num_class):\n",
    "    best_accuracy = 0\n",
    "    for j in range(num_class):\n",
    "      current_accuracy = ((cluster_label == i) == (label == j)).mean()\n",
    "      if current_accuracy > best_accuracy:\n",
    "        if best_accuracy == 0:\n",
    "          best_accuracy = current_accuracy\n",
    "          true_class.append(j)\n",
    "        else:\n",
    "          best_accuracy = current_accuracy\n",
    "          true_class[-1] = j\n",
    "\n",
    "  temp_cluster_label = np.copy(cluster_label)\n",
    "  for i in range(len(true_class)):\n",
    "    cluster_label[(temp_cluster_label == i)] = true_class[i]\n",
    "  return cluster_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mj0G0TngIGG6"
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering(num_cluster, data, label, label_bool = False):\n",
    "  print('\\n\\ninitializing kmeans clustering')\n",
    "  kmeans = KMeans(init='random', n_clusters=num_cluster, n_init=10) \n",
    "  # list of scores from kmeans method (negative sum of distance squared from cluster center)\n",
    "  cluster_label = kmeans.fit_predict(data)\n",
    "\n",
    "  if label_bool == True:\n",
    "    cluster_label = pseudolabel_unscrambler(label, cluster_label)\n",
    "    print('plots of clusters with true labels')\n",
    "    plot_features(data, label)\n",
    "    accuracy = (cluster_label == label).mean()\n",
    "    print('kmeans clustering accuracy is ', accuracy)\n",
    "  print('plots of clusters with pseudolabels')\n",
    "  plot_features(data, cluster_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5r2wUEv5rGY"
   },
   "outputs": [],
   "source": [
    "def gmm_clustering(num_cluster, data, label, label_bool = False):\n",
    "  print('\\n\\ninitializing gmm clustering')\n",
    "  gmm = GaussianMixture(n_components=num_cluster, n_init=10)\n",
    "  cluster_label = gmm.fit_predict(data)\n",
    "\n",
    "  # plots 2D slices of the features\n",
    "  if label_bool == True:\n",
    "    cluster_label = pseudolabel_unscrambler(label, cluster_label)\n",
    "    print('plots of clusters with true labels')\n",
    "    plot_features(data, label)\n",
    "    accuracy = (cluster_label == label).mean()\n",
    "    print('gmm clustering accuracy is ', accuracy)\n",
    "  print('plots of clusters with pseudolabels')\n",
    "  plot_features(data, cluster_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lnzX3jvpzH7"
   },
   "outputs": [],
   "source": [
    "def spec_clustering(num_cluster, data, label, mode, nn = 11, label_bool = False):\n",
    "  print('\\n\\ninitializing spectral clustering with ',mode)\n",
    "  if mode == 'gaussian':\n",
    "    spectral = SpectralClustering(random_state = 3, n_clusters=num_cluster, affinity = 'rbf') \n",
    "    # list of scores from kmeans method (negative sum of distance squared from cluster center)\n",
    "    cluster_label = spectral.fit_predict(data)\n",
    "  elif mode == 'knn':\n",
    "    spectral = SpectralClustering(random_state = 3, n_clusters=num_cluster, affinity = 'nearest_neighbors', n_neighbors = nn) \n",
    "    # list of scores from kmeans method (negative sum of distance squared from cluster center)\n",
    "    cluster_label = spectral.fit_predict(data)\n",
    "\n",
    "  # plots 2D slices of the features\n",
    "  if label_bool == True:\n",
    "    cluster_label = pseudolabel_unscrambler(label, cluster_label)\n",
    "    print('plots of clusters with true labels')\n",
    "    plot_features(data, label)\n",
    "    accuracy = (cluster_label == label).mean()\n",
    "    print(mode, 'spectral clustering accuracy is ', accuracy)\n",
    "  print('plots of clusters with pseudolabels')\n",
    "  plot_features(data, cluster_label)\n",
    "  return None\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RuKA_Fk-lCz"
   },
   "outputs": [],
   "source": [
    "# main function that performs preprocessing, kmeans clustering, gaussian mixture clustering, and spectral clustering\n",
    "def experiment_main(num_cluster, data, label, threshold, preprocess=False, label_bool = False):\n",
    "  # PCA preprocessing\n",
    "  if preprocess == True:\n",
    "    data = PCA_iterative(data, threshold, mode = 'threshold')\n",
    "\n",
    "  # clustering functions\n",
    "  kmeans_clustering(num_cluster, data, label, label_bool = label_bool)\n",
    "  gmm_clustering(num_cluster, data, label, label_bool = label_bool)\n",
    "  spec_clustering(num_cluster, data, label, mode = 'gaussian', label_bool = label_bool)\n",
    "  spec_clustering(num_cluster, data, label, mode = 'knn', nn = 50, label_bool = label_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9ERAJ1bCAOSB",
    "outputId": "ad83c4e7-bcee-4712-97aa-d22ccdafe18b"
   },
   "outputs": [],
   "source": [
    "### load data\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "x = []\n",
    "with open('embedded_data_training.csv') as csvfile:\n",
    "  reader = csv.reader(csvfile, delimiter = ' ')\n",
    "  for row in reader:\n",
    "    x.append([float(n) for n in row])\n",
    "\n",
    "training = np.asarray(x)\n",
    "\n",
    "x = []\n",
    "with open('embedded_data.csv') as csvfile:\n",
    "  reader = csv.reader(csvfile, delimiter = ' ')\n",
    "  for row in reader:\n",
    "    x.append([float(n) for n in row])\n",
    "\n",
    "test = np.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 0\n",
    "  \n",
    "### hyperparameters\n",
    "num_cluster = 3\n",
    "threshold = .99 # variance explained threshold for PCA preprocessing value 0 to 1\n",
    "# distance_threshold = \n",
    "# nearest_neighbors =\n",
    "\n",
    "experiment_main(num_cluster, training, label, threshold, preprocess=True, label_bool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = PCA_iterative(training, 0.99, mode = 'threshold')\n",
    "gmm = GaussianMixture(n_components=3, n_init=10).fit(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tv7GyPVXLFAR"
   },
   "outputs": [],
   "source": [
    "#   unfinished code for finding optimal clusters \n",
    "#   def kmeans_clustering(data):\n",
    "#   # the numbers of clusters to check\n",
    "#   cluster_array = np.arange(1,20)\n",
    "#   # list of kmeans models for each # of cluster in cluster_array\n",
    "#   score = []\n",
    "#   for i in cluster_array:\n",
    "#     kmeans = KMeans(init='random', n_clusters=i, n_init=100) \n",
    "#     # list of scores from kmeans method (negative sum of distance squared from cluster center)\n",
    "#     cluster_labels = kmeans.fit_predict(X)\n",
    "#     score.append(kmeans.fit(data).score(data))\n",
    "\n",
    "#   plt.plot(cluster_array, score)\n",
    "\n",
    "#   # figure(figsize=(6,6)); ax=subplot(aspect='equal')\n",
    "#   # scatter(X[:,0],X[:,1],c=kmeans.labels_,cmap=cm.rainbow);\n",
    "\n",
    "#   # C = kmeans.cluster_centers_\n",
    "#   # scatter(C[:,0],C[:,1],c='k',marker='o',s=300,alpha=0.5,edgecolor='none')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # uses KFold to get a 80/20 train/test split\n",
    "# k_fold = KFold(n_splits=5, shuffle=True) \n",
    "# for k, (train, test) in enumerate(k_fold.split(X)):\n",
    "#   train_data = data[train]\n",
    "#   test_data = data[test]\n",
    "#   train_label = label[train]\n",
    "#   test_label = label[test]\n",
    "#   break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # standardization with 0 mean and 1 stdev\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(data)\n",
    "# data = scaler.transform(data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Learning Project_Clustering",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
